{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf14a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/yhu5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7466da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from itertools import groupby, combinations\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, precision_recall_fscore_support,confusion_matrix\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "PHASES = ('starting_spans', 'hierarchical_labels')\n",
    "LABEL_DECODERS = { \\\n",
    "  PHASES[0] : { \\\n",
    "      'participants':  { 0: 'No Label', 1: 'p' },\n",
    "      'interventions': { 0: 'No Label', 1: 'i' },\n",
    "      'outcomes':      { 0: 'No Label', 1: 'o' }\n",
    "    },\n",
    "  PHASES[1]: { \\\n",
    "      'participants': { \\\n",
    "        0: 'No label',\n",
    "        1: 'Age',\n",
    "        2: 'Sex',\n",
    "        3: 'Sample-size',\n",
    "        4: 'Condition' },\n",
    "\n",
    "      'interventions': { \\\n",
    "        0: 'No label',\n",
    "        1: 'Surgical',\n",
    "        2: 'Physical',\n",
    "        3: 'Pharmacological',\n",
    "        4: 'Educational',\n",
    "        5: 'Psychological',\n",
    "        6: 'Other',\n",
    "        7: 'Control' },\n",
    "\n",
    "      'outcomes': { \\\n",
    "        0: 'No label',\n",
    "        1: 'Physical',\n",
    "        2: 'Pain',\n",
    "        3: 'Mortality',\n",
    "        4: 'Adverse-effects',\n",
    "        5: 'Mental',\n",
    "        6: 'Other' }\n",
    "    }\n",
    "}\n",
    "\n",
    "EBM_NLP = ''\n",
    "\n",
    "def fname_to_pmid(f):\n",
    "  return f.split('/')[-1].split('.')[0]\n",
    "def apply_bitmask(arr, mask):\n",
    "  return [x for x, m in zip(arr, mask) if m]\n",
    "def condense_labels(labels):\n",
    "  groups = [(k, sum(1 for _ in g)) for k,g in groupby(labels)]\n",
    "  spans = []\n",
    "  i = 0\n",
    "  for label, length in groups:\n",
    "    if label != 0:\n",
    "      spans.append((label, i, i+length))\n",
    "    i += length\n",
    "  return spans\n",
    "\n",
    "def get_test_labels(ebm_nlp_dir, phase, pio):\n",
    "  test_dir = '%s/annotations/aggregated/%s/%s/test/gold/' %(EBM_NLP, phase, pio)\n",
    "  test_fnames = glob('%s/*.ann' %test_dir)\n",
    "  print('Loading %d anns from %s' %(len(test_fnames), test_dir))\n",
    "  return { fname_to_pmid(fname): open(fname).read().split() for fname in test_fnames }\n",
    "\n",
    "#def span_overlap(pmids, pred_labels, test_labels, labels):\n",
    "#  for pmid in pmids:\n",
    "#    test_spans = condense_labels(test_labels[pmid])\n",
    "#    pred_spans = condense_labels(pred_labels[pmid])\n",
    "#    for tspan in test_spans:\n",
    "#      for pspan in pred_spans:\n",
    "#        pass\n",
    "  \n",
    "def vanilla_tokens(pmids, pred_labels, test_labels, labels):\n",
    "  y_pred = []\n",
    "  y_test = []\n",
    "  for pmid in pmids:\n",
    "    assert len(pred_labels[pmid]) == len(test_labels[pmid])\n",
    "    y_pred += pred_labels[pmid]\n",
    "    y_test += test_labels[pmid]\n",
    "  token_f1(true = y_test, pred = y_pred, labels = labels)\n",
    "\n",
    "def sw_tokens(pmids, pred_labels, test_labels, labels):\n",
    "  y_pred = []\n",
    "  y_test = []\n",
    "  for pmid in pmids:\n",
    "    assert len(pred_labels[pmid]) == len(test_labels[pmid])\n",
    "    tokens = open('%s/documents/%s.tokens' %(EBM_NLP, pmid)).read().split()\n",
    "    token_mask = [t in stops for t in tokens]\n",
    "    y_pred += apply_bitmask(pred_labels[pmid], token_mask)\n",
    "    y_test += apply_bitmask(test_labels[pmid], token_mask)\n",
    "  token_f1(true = y_test, pred = y_pred, labels = labels)\n",
    "\n",
    "def eval_labels(ebm_nlp_dir, pred_labels, phase, pio, eval_func = vanilla_tokens):\n",
    "  global EBM_NLP\n",
    "  EBM_NLP = ebm_nlp_dir\n",
    "\n",
    "  print('Evaluating labels for %s %s' %(phase, pio))\n",
    "  test_labels = get_test_labels(EBM_NLP, phase, pio)\n",
    "  pmids = set(test_labels.keys()) & set(pred_labels.keys())\n",
    "  print('Checking labels for %d pmids (out of %d possible test docs)' %(len(pmids), len(test_labels)))\n",
    "\n",
    "  labels = set(LABEL_DECODERS[phase][pio].keys())\n",
    "  labels.remove(0)\n",
    "  labels = [str(l) for l in labels]\n",
    "\n",
    "  eval_func(pmids, pred_labels, test_labels, labels)\n",
    "\n",
    "def get_f1(prec, rec):\n",
    "  return 2*prec*rec/(prec+rec)\n",
    "\n",
    "def token_f1(true, pred, labels):\n",
    "\n",
    "  class_scores = zip(labels, precision_score(true,pred, labels = labels,average=None), recall_score(true,pred, labels = labels,average=None))\n",
    "  for label, prec, rec in class_scores:\n",
    "    print ('{label}\\t{f1:.3f}\\t{prec:.3f}\\t{rec:.3f}'.format(label=label,f1=get_f1(prec, rec),prec=prec,rec=rec))\n",
    "    \n",
    "  prec = precision_score(true, pred, labels = labels, average='micro')\n",
    "  rec = recall_score(true, pred, labels = labels, average='micro')\n",
    "  f1 = get_f1(prec, rec)\n",
    "  print ('overall\\t{f1:.3f}\\t{prec:.3f}\\t{rec:.3f}'.format(f1=f1,prec=prec,rec=rec))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef024d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "770068af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yhu5/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/yhu5/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_39078/680363953.py:110: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 2*prec*rec/(prec+rec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-i\t0.652\t0.750\t0.576\n",
      "B-p\tnan\t0.000\t0.000\n",
      "I-p\t0.827\t0.914\t0.755\n",
      "B-o\tnan\t0.000\t0.000\n",
      "I-o\t0.709\t0.614\t0.838\n",
      "B-i\tnan\t0.000\t0.000\n",
      "overall\t0.732\t0.730\t0.734\n"
     ]
    }
   ],
   "source": [
    "gold = []\n",
    "pre = []\n",
    "with open('/home/yhu5/jianfu_NER/ner_ft_bert/data/EBM_raw_starting_level/output_1e-5_5ep/fold1/output_update_256/microsoft-BiomedNLP-PubMedBERT-base-uncased-abstract/predict_test_label.txt','r') as f:\n",
    "    for line in f:\n",
    "        if not line.startswith('-DOCSTART-') and not line=='\\n':\n",
    "            gold.append(line.split()[2])\n",
    "            pre.append(line.split()[1])\n",
    "token_f1(true = gold, pred = pre, labels = ['I-i', 'B-p', 'I-p', 'B-o', 'I-o', 'B-i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e536b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-P\t0.951\t0.919\t0.986\n",
      "I-I\t0.707\t0.898\t0.582\n",
      "I-C\t0.769\t0.882\t0.682\n",
      "I-O\t0.918\t0.992\t0.854\n",
      "overall\t0.908\t0.958\t0.862\n",
      "\n",
      "\n",
      "I-P\t0.959\t0.988\t0.931\n",
      "I-I\t0.919\t0.919\t0.919\n",
      "I-C\t0.818\t1.000\t0.692\n",
      "I-O\t0.916\t0.879\t0.956\n",
      "overall\t0.931\t0.927\t0.935\n",
      "\n",
      "\n",
      "I-P\t0.844\t0.906\t0.789\n",
      "I-I\t0.824\t0.857\t0.793\n",
      "I-C\t0.760\t0.950\t0.633\n",
      "I-O\t0.913\t0.909\t0.916\n",
      "overall\t0.862\t0.897\t0.829\n",
      "\n",
      "\n",
      "I-P\t0.969\t0.943\t0.996\n",
      "I-I\t0.853\t0.844\t0.863\n",
      "I-C\t0.828\t0.706\t1.000\n",
      "I-O\t0.878\t0.866\t0.890\n",
      "overall\t0.905\t0.886\t0.924\n",
      "\n",
      "\n",
      "I-P\t0.792\t0.857\t0.736\n",
      "I-I\t0.824\t0.856\t0.794\n",
      "I-C\t0.870\t0.833\t0.909\n",
      "I-O\t0.825\t0.780\t0.876\n",
      "overall\t0.811\t0.837\t0.785\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    gold = []\n",
    "    pre = []\n",
    "    with open('/home/yhu5/jianfu_NER/ner_ft_bert/data/pure_AD_5fold_section_filtered/output_major_revision_check/fold{}/output_update_256/microsoft-BiomedNLP-PubMedBERT-base-uncased-abstract/predict_test_label.txt'.format(i+1),'r') as f:\n",
    "        for line in f:\n",
    "            if not line.startswith('-DOCSTART-') and not line=='\\n' and len(line.split())==3:\n",
    "                gold.append(line.split()[2].replace('B-','I-'))\n",
    "                pre.append(line.split()[1].replace('B-','I-'))\n",
    "    token_f1(true = gold, pred = pre, labels = ['I-P','I-I','I-C',  'I-O'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc91881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c2637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
